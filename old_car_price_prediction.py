# -*- coding: utf-8 -*-
"""Old_Car_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10WPE-1mMY5zOcycwFuV9BXRVpVA-8SK4
"""

import numpy as np
import pandas as pd

df = pd.read_csv('car-data.csv')

df.sample(10)

df.shape

df.isnull().sum()

df["car_age"] = 2021 - df["year"]

df.head()

df.year.value_counts()

import matplotlib.pyplot as plt
import seaborn as sns

year_counts = pd.DataFrame(data = df.year.value_counts())

year_counts.reset_index(inplace=True)

year_counts.rename(columns={'index':'year','year':'counts'},inplace=True)
year_counts

fig, ax = plt.subplots(figsize=(10,8))
sns.barplot(x='year',y='counts',data=year_counts)

sns.distplot(df["price"],bins=15)

sns.boxplot(df["price"])

df[df["price"]>df["price"].quantile(.99)]

plt.hist(df["price"])
plt.show()

df.transmission.value_counts()

sns.catplot(x='transmission',kind="count",data=df)

plt.hist(df["mileage"])
plt.show()

df['mileage'].plot(kind='box')

df[df["mileage"]>df["mileage"].quantile(.99)]

df.fuelType.value_counts()

sns.countplot(y='fuelType',data=df,color='c')

sns.distplot(df['tax'])

plt.boxplot(df['tax'])
plt.show()

sns.boxplot(df['tax'])

plt.boxplot(df['mpg'])
plt.show()

plt.hist(df["mpg"],bins=10)
plt.show()

sns.boxplot(df['engineSize'])

plt.hist(df['car_age'],bins=20)
plt.show()

sns.boxplot(df['car_age'])

plt.boxplot(df['car_age'])
plt.show()

df = df.drop(['year'],axis=1)
df.head()

df.shape

df = df.replace({'Automatic': 0, 'Manual': 1, 'Semi-Auto': 2})

df = df.replace({'Diesel': 0, 'Petrol': 1, 'Hybrid': 2, 'Other': 3})

#df_f = pd.concat([df,df_dummy],axis=1)

#df_f.sample(5)

#df_f = df_f.drop(["transmission","fuelType"],axis=1)

#df_f.head()

#df_f.shape

plt.figure(figsize=(16,10))
sns.heatmap(df.corr(),annot=True)

X=df.drop(["price"],axis=1)
X.head()

y = df["price"]
y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)

X_train.shape, X_test.shape

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)

lin_reg.score(X_train,y_train)

lin_reg.score(X_test,y_test)

lin_reg_predict = lin_reg.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score

print("MAE:", mean_absolute_error(y_test,lin_reg_predict))
print("MSE:", mean_squared_error(y_test,lin_reg_predict))
print("RMSE:", np.sqrt(mean_squared_error(y_test,lin_reg_predict)))

r2_score(y_test,lin_reg_predict)

from sklearn.ensemble import RandomForestRegressor
rfr = RandomForestRegressor()
rfr.fit(X_train,y_train)

rfr.score(X_train,y_train)

rfr.score(X_test,y_test)

rfr_predict = rfr.predict(X_test)

print("MAE:", mean_absolute_error(y_test,rfr_predict))
print("MSE:", mean_squared_error(y_test,rfr_predict))
print("RMSE:", np.sqrt(mean_squared_error(y_test,rfr_predict)))

r2_score(y_test,rfr_predict)

import xgboost as xgb
xgboost = xgb.XGBRegressor(random_state=1,learning_rate=0.1)
xgboost.fit(X_train,y_train)

xgboost.score(X_test,y_test)

xgboost.score(X_train,y_train)

xgb_predict = xgboost.predict(X_test)

print("MAE:", mean_absolute_error(y_test,xgb_predict))
print("MSE:", mean_squared_error(y_test,xgb_predict))
print("RMSE:", np.sqrt(mean_squared_error(y_test,xgb_predict)))

r2_score(y_test,xgb_predict)

import pickle
f = open('rfr.pickle', 'wb')
pickle.dump(rfr, f)
f.close()
import pickle
f = open('xgboost.pickle', 'wb')
pickle.dump(xgboost, f)
f.close()